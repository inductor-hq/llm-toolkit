"""Functions to generate and execute SQL from text."""

import re
import textwrap
from typing import Any, Dict

import inductor
import openai

import database
import prompts


openai_client = openai.OpenAI()


def generate_sql(analytics_text: str) -> str:
    """Returns SQL generated from the LLM.

    Args:
        analytics_text: Input text describing a data analytics question or
            request.
    """
    db_schema = database.get_sql_schema()
    db_type = database.sql_database_type
    prompt = textwrap.dedent(f"""\
    Given the following {db_type} Database Table Schema:

    ```
    {db_schema}
    ```

    Generate a {db_type} statement that accomplishes:
    **{analytics_text}**

    All *Decimal* and *Real* values should be rounded to 2 decimal places
    The SQL statement should end with a ';'
    *Only* return the raw SQL statement
    """)

    completion = openai_client.chat.completions.create(
        model=inductor.hparam("model", "gpt-4o"),
        messages=[
            {"role": "system",
                "content": prompts.SYSTEM_PROMPT_DEFAULT},
            {"role": "user", "content": prompt}
        ]
    )
    raw_sql = completion.choices[0].message.content
    inductor.log(raw_sql)
    return raw_sql


def _process_generated_sql(generated_sql: str) -> str:
    """Returns a SQL statement by processing the LLM generated SQL.

    Sometimes the LLM generated SQL will have some formatting that makes
    the response invalid SQL (eg. ```sql\nSelect ...;\n```). This function
    does some light processing to just return the valid SQL statment.

    Args:
        generated_sql: The SQL statment generated from the LLM which
            may be invalid, but "almost" correct.
    """
    left_stripped_sql = (
        re.sub(r"^.*?SELECT", "SELECT", generated_sql, flags=re.DOTALL))
    processed_sql = re.sub(r";.*?$", ";", left_stripped_sql, flags=re.DOTALL)
    if not processed_sql.endswith(";"):
        return processed_sql + ";"
    return processed_sql


@inductor.logger
def get_analytics_results(analytics_text: str) -> Dict[str, Any]:
    """Retrieve results via an LLM generated SQL query.

    Args:
        analytics_text: Input text describing a data analytics question or
            request.

    Returns:
        A dictionary giving a JSON-serializable structure which
        contains the results of running the LLM generated SQL statement
        (if possible) as well as other metadata. The dictionary structure
        will resemble as follows:
        {
            input_text: The analytics query provided to the LLM.
            generated_sql: The unprocessed SQL generated by the LLM.
            processed_sql: The SQL query after light processing.
            valid_sql: Boolean that is True if the SQL statement is valid
                and executable.
            column_headers: A list of the column names returned by executing
                the SQL query (if possible).
            results: A list of lists containing the rows returned by
                executing the SQL query (if possible).
        }
    """
    output = {}
    output["input_text"] = analytics_text
    raw_sql = generate_sql(analytics_text)
    output["generated_sql"] = raw_sql
    processed_sql = _process_generated_sql(raw_sql)
    output["processed_sql"] = processed_sql

    if database.is_valid_sql(processed_sql):
        output["valid_sql"] = True
        columns, results = (
            database.get_sql_results_headers_and_values(processed_sql))
        output["column_headers"] = columns
        output["results"] = results
    else:
        output["valid_sql"] = False
    return output
